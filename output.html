<html>
    <head>
    <style>
        .card { margin: 10px 0; padding: 10px; background: #e8f4fd; border-radius: 5px; cursor: pointer; }
        .answer { display: none; }
        .card:hover .answer { display: inline; }
    </style>
    </head>
    <body style="font-family:Arial;padding:40px;max-width:800px;margin:0 auto;line-height:1.6;">
        <h1>Learning Materials</h1>
        <pre style="background:#f5f5f5;padding:20px;border-radius:5px;white-space:pre-wrap;">## Retrieval-Augmented Generation (RAG)<br><br><b>1. Summary:</b><br><br>Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by combining their generative capabilities with external information retrieval.  Traditional LLMs generate text solely based on their internal knowledge, which can lead to inaccuracies or outdated information. RAG addresses this by first retrieving relevant context from external sources (e.g., databases, websites) based on the user's prompt. This retrieved information is then fed to the LLM, allowing it to generate a more informed and accurate response grounded in external evidence.  This two-step process of retrieval and generation improves the reliability and factual accuracy of LLM outputs.<br><br><b>2. ASCII Diagram:</b><br><br><br>+-----------------+     +-----------------+     +-----------------+      +-----------------+<br>|  User Prompt    | --> |   Retriever     | --> | Relevant Context | --> | LLM (Generator) | --> |    Response     |<br>+-----------------+     +-----------------+     +-----------------+      +-----------------+<br>                                                         ^<br>                                                         |<br>                                                         +-----------------+<br>                                                         | External Sources |<br>                                                         +-----------------+<br><br><br><br><br><b>3. Flashcards:</b><br><br><div class="card">ðŸ§  What does RAG stand for?<span class="answer">ðŸ’¡ Retrieval-Augmented Generation</span></div><br><br><div class="card">ðŸ§  What is the core idea behind RAG?<span class="answer">ðŸ’¡ Combining information retrieval with LLM generation.</span></div><br><br><div class="card">ðŸ§  What problem does RAG address?<span class="answer">ðŸ’¡ Inaccuracies and outdated information in LLM-generated text.</span></div><br><br><div class="card">ðŸ§  What is the role of the "Retriever" in RAG?<span class="answer">ðŸ’¡ To find relevant information from external sources based on the user prompt.</span></div><br><br><div class="card">ðŸ§  What are examples of external sources used in RAG?<span class="answer">ðŸ’¡ Databases, websites, knowledge graphs.</span></div><br><br><div class="card">ðŸ§  How does RAG improve LLM outputs?<span class="answer">ðŸ’¡ By grounding the generated text in external evidence.</span></div><br><br><div class="card">ðŸ§  What is a "prompt" in the context of LLMs?<span class="answer">ðŸ’¡ The user's input or query to the LLM.</span></div><br><br><div class="card">ðŸ§  What is the "Generation" part of RAG?<span class="answer">ðŸ’¡ The LLM generating text based on the retrieved context and the prompt.</span></div><br><br><div class="card">ðŸ§  What is a key difference between traditional LLMs and RAG?<span class="answer">ðŸ’¡ RAG uses external information, while traditional LLMs rely solely on internal knowledge.</span></div><br><br><div class="card">ðŸ§  Who presented the anecdote about children's questions and LLMs in this context?<span class="answer">ðŸ’¡ Marina Danilevsky, Senior Research Scientist at IBM Research.</span></div><br><br><br><b>4. MCQs:</b><br><br>Q1: What does the "R" in RAG stand for?<br><br>a) Recursive <br>b) Retrieval âœ… <br>c) Recurrent <br>d) Real-time<br><br>Q2: RAG primarily aims to improve which aspect of LLMs?<br><br>a) Speed <br>b) Creativity <br>c) Accuracy âœ… <br>d) Size<br><br>Q3: The "Retriever" component in RAG interacts with:<br><br>a) Only the LLM <br>b) Only the user prompt <br>c) External sources âœ… <br>d) Internal LLM parameters<br><br>Q4: What is passed to the LLM in RAG?<br><br>a) Only the user prompt <br>b) Only retrieved context <br>c) Both the prompt and retrieved context âœ… <br>d) Neither the prompt nor the context<br><br>Q5:  What is the final output of the RAG framework?<br><br>a) Retrieved context <br>b) User prompt <br>c) LLM-generated response âœ… <br>d)  List of external sources<br><br><br>Q6: Which issue with LLMs does RAG aim to solve?<br><br>a) Slow response times <br>b) Difficulty understanding complex prompts <br>c)  Hallucinations and outdated information âœ… <br>d) Limited vocabulary<br><br>Q7: What is a benefit of using RAG with LLMs?<br><br>a) Reduced computational cost <br>b) Increased creativity <br>c) Improved factual accuracy âœ… <br>d) Simplified model training<br><br><br>Q8: Which of these is NOT a component of RAG?<br><br>a) Retriever <br>b) Generator <br>c) Translator âœ… <br>d) External sources<br><br><br>Q9: Marina Danilevsky's anecdote about children's questions highlights:<br><br>a) The speed of LLMs <br>b) The limitations of current LLM knowledge âœ… <br>c) The complexity of user prompts <br>d) The need for more powerful hardware<br><br>Q10: In RAG, the LLM is instructed to:<br><br>a) Generate text immediately <br>b) Retrieve relevant content first âœ… <br>c) Ignore the user prompt <br>d) Focus only on internal knowledge<br><br><br><b>5. External Links:</b><br><br>1. [Retrieval-Augmented Generation (RAG): <a href="https://www.promptingguide.ai/techniques/rag](https://www.promptingguide.ai/techniques/rag)" target="_blank">https://www.promptingguide.ai/techniques/rag](https://www.promptingguide.ai/techniques/rag)</a><br>2. [LangChain for LLM Application Development: <a href="https://python.langchain.com/en/latest/index.html](https://python.langchain.com/en/latest/index.html)" target="_blank">https://python.langchain.com/en/latest/index.html](https://python.langchain.com/en/latest/index.html)</a>  (Often used to implement RAG)<br>3. [Haystack: An open-source NLP framework: <a href="https://haystack.deepset.ai/](https://haystack.deepset.ai/)" target="_blank">https://haystack.deepset.ai/](https://haystack.deepset.ai/)</a> (Includes RAG functionality)<br>4. [LlamaIndex: Connect LLMs to your data: <a href="https://gpt-index.readthedocs.io/en/latest/](https://gpt-index.readthedocs.io/en/latest/)" target="_blank">https://gpt-index.readthedocs.io/en/latest/](https://gpt-index.readthedocs.io/en/latest/)</a>  (Another tool for building RAG applications)<br>5. [IBM Research: <a href="https://research.ibm.com/](https://research.ibm.com/)" target="_blank">https://research.ibm.com/](https://research.ibm.com/)</a> (Explore more about IBM's work in AI and LLMs) <br></pre>
    </body>
    </html>